{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ff356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "#most likely need to !pip install pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480cc463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio segments\n",
    "dot = AudioSegment.from_wav('dot.wav')\n",
    "dash = AudioSegment.from_wav('dash.wav')\n",
    "space = AudioSegment.from_wav('silent_half-second.wav')\n",
    "silent = AudioSegment.from_wav('silent_quarter-second.wav')\n",
    "\n",
    "#list for conversion\n",
    "morse_dict = { 'A':'.-', 'B':'-...',\n",
    "               'C':'-.-.', 'D':'-..', 'E':'.',\n",
    "               'F':'..-.', 'G':'--.', 'H':'....',\n",
    "               'I':'..', 'J':'.---', 'K':'-.-',\n",
    "               'L':'.-..', 'M':'--', 'N':'-.',\n",
    "               'O':'---', 'P':'.--.', 'Q':'--.-',\n",
    "               'R':'.-.', 'S':'...', 'T':'-',\n",
    "               'U':'..-', 'V':'...-', 'W':'.--',\n",
    "               'X':'-..-', 'Y':'-.--', 'Z':'--..'}    \n",
    "# mainTranslate()\n",
    "# Audio('output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86c7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion function\n",
    "def eng2morse(english):\n",
    "    morse_text = ''\n",
    "    morse_sound = AudioSegment.empty() \n",
    "    i = 0\n",
    "    \n",
    "    #loops through word\n",
    "    #adds space after each letter, 2 spaces for words\n",
    "    while(i<len(english)):\n",
    "        if(english[i] != \" \"):\n",
    "            morse_text += morse_dict[english[i]] + ' '\n",
    "        else:\n",
    "            morse_text += ' '\n",
    "        i+=1\n",
    "\n",
    "    j=0\n",
    "    #loops through morse, adds segments to empty audio file for each dot or dash\n",
    "    # 0.25 second of silence between dots and dashes\n",
    "    # 0.75 seconds between letters\n",
    "    #these are true to morse units of measurement\n",
    "    while(j<len(morse_text)):\n",
    "        if(morse_text[j] == \".\"):\n",
    "            morse_sound += dot + silent\n",
    "            #print('dot')\n",
    "        elif(morse_text[j] == \"-\"):\n",
    "            morse_sound += dash + silent\n",
    "            #print('dash')\n",
    "        else:\n",
    "            if(morse_text[j-1] == \" \"):  #if last letter was a space, meaning 2 spaces in a row, then must add more time between words\n",
    "                morse_sound += space + space + silent\n",
    "                #print('word space')\n",
    "            elif(j == len(morse_text)-1):  #last letter, no need for extra silence after\n",
    "                break\n",
    "            else:\n",
    "                morse_sound += silent\n",
    "                #print('letter space')\n",
    "        j+=1\n",
    "    \n",
    "    #exporting full audio signal\n",
    "    morse_sound.export(\"sound.wav\", format=\"wav\")\n",
    "    fs, data = wavfile.read('sound.wav')\n",
    "    return morse_text, fs, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ce9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main for running functions\n",
    "def mainTranslate(input_str: str, wav_filename: str = \"output\"):\n",
    "    # english = input(\"Word to be translated(from edge detection system): \")\n",
    "    english = input_str\n",
    "    output, output_fs, output_data= eng2morse(english.upper())\n",
    "    print(output)\n",
    "    wavfile.write(wav_filename + \".wav\", output_fs, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a76fe7d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numFrames):\n\u001b[0;32m     27\u001b[0m     frame \u001b[38;5;241m=\u001b[39m data[i \u001b[38;5;241m*\u001b[39m FRAME_SIZE : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m FRAME_SIZE]\n\u001b[1;32m---> 28\u001b[0m     curFft \u001b[38;5;241m=\u001b[39m ece420ProcessFrame(frame)\n\u001b[0;32m     29\u001b[0m     bmp[i, :] \u001b[38;5;241m=\u001b[39m curFft\n\u001b[0;32m     30\u001b[0m bmp_scaled \u001b[38;5;241m=\u001b[39m bmp\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(bmp) \u001b[38;5;66;03m#scaling the result \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m, in \u001b[0;36mece420ProcessFrame\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(FRAME_SIZE): \u001b[38;5;66;03m# windowing by convolution \u001b[39;00m\n\u001b[0;32m     16\u001b[0m     win \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.54\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.46\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m/\u001b[39m(FRAME_SIZE\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 17\u001b[0m     w_result[i] \u001b[38;5;241m=\u001b[39m win\u001b[38;5;241m*\u001b[39mframe[i] \u001b[38;5;66;03m#window\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     pad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(w_result, (\u001b[38;5;241m0\u001b[39m,PAD), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#zero padding \u001b[39;00m\n\u001b[0;32m     19\u001b[0m     square \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(np\u001b[38;5;241m.\u001b[39mabs(fft(w_result, FFT_SIZE))) \u001b[38;5;66;03m# FFT and magnitude squared of fft\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "##Did not have time yet/don't think were going to use a Spectrogram, but if we do this is where I would begin to visualize it\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io.wavfile import read, write\n",
    "# from numpy.fft import fft, ifft\n",
    "# FRAME_SIZE = 1024\n",
    "# ZP_FACTOR = 2\n",
    "# FFT_SIZE = FRAME_SIZE * ZP_FACTOR\n",
    "# PAD = FFT_SIZE - FRAME_SIZE\n",
    "# ################## YOUR CODE HERE ######################\n",
    "# def ece420ProcessFrame(frame):\n",
    "#     curFft = np.zeros(FFT_SIZE)\n",
    "#     w_result = np.zeros(FFT_SIZE)\n",
    "#     for i in range(FRAME_SIZE): # windowing by convolution \n",
    "#         win = 0.54 - 0.46 * np.cos(2*np.pi*i/(FRAME_SIZE-1))\n",
    "#         w_result[i] = win*frame[i] #window\n",
    "#         pad = np.pad(w_result, (0,PAD), 'constant') #zero padding \n",
    "#         square = np.square(np.abs(fft(w_result, FFT_SIZE))) # FFT and magnitude squared of fft\n",
    "#         curFft = np.log10(square) #Log()\n",
    "#     return curFft[:FRAME_SIZE]\n",
    "# ################# GIVEN CODE BELOW #####################\n",
    "# Fs, data = read('output.wav')\n",
    "# numFrames = int(len(data) / FRAME_SIZE)\n",
    "# bmp = np.zeros((numFrames, FRAME_SIZE))\n",
    "# for i in range(numFrames):\n",
    "#     frame = data[i * FRAME_SIZE : (i + 1) * FRAME_SIZE]\n",
    "#     curFft = ece420ProcessFrame(frame)\n",
    "#     bmp[i, :] = curFft\n",
    "# bmp_scaled = bmp/np.max(bmp) #scaling the result \n",
    "# plt.figure()\n",
    "# plt.pcolormesh(bmp_scaled.T, vmin=0, vmax = 1)\n",
    "# plt.axis('tight')\n",
    "# plt.show()\n",
    "\n",
    "# from IPython.display import Audio\n",
    "# Audio(data,rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36181e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
